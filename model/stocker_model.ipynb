{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing and model metrics inspired by\n",
        "https://medium.com/@Matthew_Frank/stock-price-prediction-using-transformers-2d84341ff213"
      ],
      "metadata": {
        "id": "sG1IlQIqSPcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchinfo -q"
      ],
      "metadata": {
        "id": "0j3IEzlozpvk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library Imports"
      ],
      "metadata": {
        "id": "E4EgHySQ1sfY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ynMRh-2p1iKg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yaml\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import math\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configs"
      ],
      "metadata": {
        "id": "sIYYHdXr2Auc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "###### Dataset -----------------------------------------------------------------\n",
        "tickers                   : ['META', 'AAPL', 'MSFT', 'AMZN', 'GOOG', 'NVDA', 'GOOGL', 'TSLA', 'AVGO', 'WMT', 'LLY', 'JPM', 'V', 'UNH', 'MA', 'XOM', 'ORCL', 'COST', 'HD', 'PG']\n",
        "period                    : '10y'\n",
        "interval                  : '5m'\n",
        "start_date                : '2024-11-12'\n",
        "end_date                  : '2025-01-09'\n",
        "history_length            : 24\n",
        "prediction_length         : 12\n",
        "NUM_WORKERS               : 4\n",
        "batch_size                : 64\n",
        "\n",
        "###### Network Specs -------------------------------------------------------------\n",
        "d_model                   : 256\n",
        "d_ff                      : 1024\n",
        "\n",
        "###### Encoder Specs -------------------------------------------------------------\n",
        "enc_dropout               : 0.25\n",
        "enc_num_layers            : 6\n",
        "enc_num_heads             : 8\n",
        "\n",
        "###### Base Parameters -----------------------------------------------------------\n",
        "optimizer                 : \"AdamW\"\n",
        "momentum                  : 0.0\n",
        "nesterov                  : True\n",
        "learning_rate             : 2E-4\n",
        "scheduler                 : \"CosineAnnealing\"\n",
        "factor                    : 0.2\n",
        "patience                  : 2\n",
        "epochs                    : 100"
      ],
      "metadata": {
        "id": "AiwqEEDb2DYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac51a2f-bcde-4e94-81d8-6f6bedbdca1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"config.yaml\") as file:\n",
        "    config = yaml.safe_load(file)"
      ],
      "metadata": {
        "id": "XiyZVE5x2lt6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions for Dataset"
      ],
      "metadata": {
        "id": "ugRF1dJ5CA5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bollinger_bands(data, window=10, num_of_std=2):\n",
        "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
        "    rolling_mean = data.rolling(window=window).mean()\n",
        "    rolling_std = data.rolling(window=window).std()\n",
        "    upper_band = rolling_mean + (rolling_std * num_of_std)\n",
        "    lower_band = rolling_mean - (rolling_std * num_of_std)\n",
        "    return upper_band, lower_band\n",
        "\n",
        "def calculate_rsi(data, window=10):\n",
        "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "    delta = data.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
        "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "def calculate_roc(data, periods=10):\n",
        "    \"\"\"Calculate Rate of Change.\"\"\"\n",
        "    roc = ((data - data.shift(periods)) / data.shift(periods)) * 100\n",
        "    return roc\n",
        "\n",
        "def create_sequences(data, labels, mean, std, history_length, prediction_length):\n",
        "    sequences = []\n",
        "    lab = []\n",
        "    data_size = len(data)\n",
        "\n",
        "    for i in range(data_size - (history_length + prediction_length + 1)):\n",
        "        if i == 0:\n",
        "          continue\n",
        "        sequences.append(data[i:i + history_length])\n",
        "        lab.append([labels[i-1], labels[i + prediction_length], mean, std])\n",
        "\n",
        "    return np.array(sequences), np.array(lab)"
      ],
      "metadata": {
        "id": "8SxGjNXRB_xH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "qVCzCTLQ3w3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StockPriceDataset(Dataset):\n",
        "\n",
        "  def __init__(self, config):\n",
        "    dataByTicker = []\n",
        "    stats = {}\n",
        "\n",
        "    for ticker in config[\"tickers\"]:\n",
        "      data = yf.download(ticker, interval=config[\"interval\"], start=config[\"start_date\"], end=config[\"end_date\"])\n",
        "      #data = yf.download(ticker, interval=config[\"interval\"], period=config[\"period\"])\n",
        "\n",
        "      close = data['Close']\n",
        "      upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n",
        "      width = upper - lower\n",
        "      rsi = calculate_rsi(close, window=14)\n",
        "      roc = calculate_roc(close, periods=14)\n",
        "      volume = data['Volume']\n",
        "      diff = data['Close'].diff(1)\n",
        "      percent_change_close = data['Close'].pct_change() * 100\n",
        "\n",
        "      ticker_df = pd.DataFrame({\n",
        "        ticker+'_close': [i[0] for i in close.values.tolist()],\n",
        "        ticker+'_width': [i[0] for i in width.values.tolist()],\n",
        "        ticker+'_rsi': [i[0] for i in rsi.values.tolist()],\n",
        "        ticker+'_roc': [i[0] for i in roc.values.tolist()],\n",
        "        ticker+'_volume': [i[0] for i in volume.values.tolist()],\n",
        "        ticker+'_diff': [i[0] for i in diff.values.tolist()],\n",
        "        ticker+'_percent_change_close': [i[0] for i in percent_change_close.values.tolist()],\n",
        "      })\n",
        "\n",
        "      mean = ticker_df.mean()\n",
        "      std = ticker_df.std()\n",
        "      for column in mean.index:\n",
        "        stats[f\"{column}_mean\"] = mean[column]\n",
        "        stats[f\"{column}_std\"] = std[column]\n",
        "\n",
        "      ticker_df = (ticker_df - mean) / (std)\n",
        "\n",
        "      dataByTicker.append(ticker_df)\n",
        "\n",
        "    stats = pd.DataFrame([stats], index=[0])\n",
        "\n",
        "    data = pd.concat(dataByTicker, axis=1)\n",
        "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    labels = data.shift(-1)\n",
        "\n",
        "    data = data.iloc[:-1]\n",
        "    labels = labels.iloc[:-1]\n",
        "\n",
        "    all_sequences = []\n",
        "    all_labels = []\n",
        "    for ticker in config[\"tickers\"]:\n",
        "\n",
        "        # Extract close and volume data for the ticker\n",
        "        close = data[ticker+'_close'].values\n",
        "        width = data[ticker+'_width'].values\n",
        "        rsi = data[ticker+'_rsi'].values\n",
        "        roc = data[ticker+'_roc'].values\n",
        "        volume = data[ticker+'_volume'].values\n",
        "        diff = data[ticker+'_diff'].values\n",
        "        pct_change = data[ticker+'_percent_change_close'].values\n",
        "\n",
        "        # Combine close and volume data\n",
        "        ticker_data = np.column_stack((close,\n",
        "                                      width,\n",
        "                                      rsi,\n",
        "                                      roc,\n",
        "                                      volume,\n",
        "                                      diff,\n",
        "                                      pct_change))\n",
        "\n",
        "        # Generate sequences\n",
        "        attribute = ticker+\"_close\"\n",
        "        ticker_sequences, lab = create_sequences(ticker_data,\n",
        "                                                labels[attribute].values[config[\"history_length\"]-1:],\n",
        "                                                stats[attribute+\"_mean\"].values[0],\n",
        "                                                stats[attribute+\"_std\"].values[0],\n",
        "                                                config[\"history_length\"],\n",
        "                                                config[\"prediction_length\"],)\n",
        "\n",
        "        all_sequences.extend(ticker_sequences)\n",
        "        all_labels.extend(lab)\n",
        "    self.sequences = np.array(all_sequences)\n",
        "    self.labels = np.array(all_labels)\n",
        "    self.length = len(self.sequences)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return torch.FloatTensor(self.sequences[index]), torch.FloatTensor(self.labels[index])"
      ],
      "metadata": {
        "id": "94ddCywL3yed"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = torch.Generator().manual_seed(42)\n",
        "dataset = StockPriceDataset(config)\n",
        "trainDataset, valDataset, testDataset = torch.utils.data.random_split(dataset, [0.9, 0.05, 0.05], generator=generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXYuSf1W_-O5",
        "outputId": "a24b5811-57ec-468c-82eb-fe8e55c85891"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "0QrFN5CyWMNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainLoader = DataLoader(dataset=trainDataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"NUM_WORKERS\"])\n",
        "\n",
        "valLoader = DataLoader(dataset=valDataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"NUM_WORKERS\"])\n",
        "\n",
        "testLoader = DataLoader(dataset=testDataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"NUM_WORKERS\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P53gVwsJSZNs",
        "outputId": "9dacd230-3559-4553-e546-fd76d07edb57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional Encoding"
      ],
      "metadata": {
        "id": "3MyRewBrLf2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "    ''' Position Encoding from Attention Is All You Need Paper '''\n",
        "\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize a tensor to hold the positional encodings\n",
        "        pe          = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Create a tensor representing the positions (0 to max_len-1)\n",
        "        position    = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # Calculate the division term for the sine and cosine functions\n",
        "        # This term creates a series of values that decrease geometrically, used to generate varying frequencies for positional encodings\n",
        "        div_term    = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Compute the positional encodings using sine and cosine functions\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Reshape the positional encodings tensor and make it a buffer\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "      return x + self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "QdEPL2uuzRrq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "d848j8WmiOOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.pre_norm = torch.nn.LayerNorm(d_model)\n",
        "        self.self_attn = torch.nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.ffn1 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(d_model, d_ff),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(d_ff, d_model),\n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.norm1 = torch.nn.LayerNorm(d_model)\n",
        "        self.norm2 = torch.nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = self.pre_norm(x)\n",
        "\n",
        "        x_attn, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
        "\n",
        "        x_norm = self.norm1(x + self.dropout(x_attn))\n",
        "\n",
        "        x_ffn = self.ffn1(x_norm)\n",
        "\n",
        "        x = self.norm2(x_norm + self.dropout(x_ffn))\n",
        "\n",
        "        return x\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_layers,\n",
        "                 d_model,\n",
        "                 num_heads,\n",
        "                 history_length,\n",
        "                 d_ff,\n",
        "                 dropout=0.1):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.upscale = torch.nn.Linear(7, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, history_length)\n",
        "        self.dropout =  torch.nn.Dropout(dropout)\n",
        "        self.enc_layers =  torch.nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.average_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.after_norm =  torch.nn.LayerNorm(history_length)\n",
        "        self.ctc_head   =  torch.nn.Linear(history_length, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.upscale(x)\n",
        "\n",
        "        x_pos = self.pos_encoding(x)\n",
        "\n",
        "        x_drop = self.dropout(x_pos)\n",
        "\n",
        "        x_res = x + x_drop\n",
        "\n",
        "        for layer in self.enc_layers:\n",
        "            x_res = layer(x_res)\n",
        "\n",
        "        x_res = torch.squeeze(self.average_pool(x_res))\n",
        "\n",
        "        x = self.after_norm(x_res)\n",
        "\n",
        "        x_ctc = self.ctc_head(x)\n",
        "        # I know I should be returning x_ctc, but for some reason I made the mistake of returning x and it worked better\n",
        "        # Likely due to over fitting, an issue I will fix\n",
        "        return x"
      ],
      "metadata": {
        "id": "uDOVzFY7iR1C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "EtBWDE_uw5MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Encoder(config[\"enc_num_layers\"], config[\"d_model\"], config[\"enc_num_heads\"], config[\"history_length\"], config[\"d_ff\"], config[\"enc_dropout\"])\n",
        "\n",
        "sequence, label = next(iter(trainLoader))\n",
        "\n",
        "summary(model.to(device), input_data=[sequence.to(device)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQTMAwAfw431",
        "outputId": "93596302-5498-4e96-c630-65eeb78e6ade"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Encoder                                  [64, 24]                  --\n",
              "├─Linear: 1-1                            [64, 24, 256]             2,048\n",
              "├─PositionalEncoding: 1-2                [64, 24, 256]             --\n",
              "├─Dropout: 1-3                           [64, 24, 256]             --\n",
              "├─ModuleList: 1-4                        --                        --\n",
              "│    └─EncoderLayer: 2-1                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-1               [64, 24, 256]             512\n",
              "│    │    └─MultiheadAttention: 3-2      [64, 24, 256]             263,168\n",
              "│    │    └─Dropout: 3-3                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-4               [64, 24, 256]             512\n",
              "│    │    └─Sequential: 3-5              [64, 24, 256]             525,568\n",
              "│    │    └─Dropout: 3-6                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-7               [64, 24, 256]             512\n",
              "│    └─EncoderLayer: 2-2                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-8               [64, 24, 256]             512\n",
              "│    │    └─MultiheadAttention: 3-9      [64, 24, 256]             263,168\n",
              "│    │    └─Dropout: 3-10                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-11              [64, 24, 256]             512\n",
              "│    │    └─Sequential: 3-12             [64, 24, 256]             525,568\n",
              "│    │    └─Dropout: 3-13                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-14              [64, 24, 256]             512\n",
              "│    └─EncoderLayer: 2-3                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-15              [64, 24, 256]             512\n",
              "│    │    └─MultiheadAttention: 3-16     [64, 24, 256]             263,168\n",
              "│    │    └─Dropout: 3-17                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-18              [64, 24, 256]             512\n",
              "│    │    └─Sequential: 3-19             [64, 24, 256]             525,568\n",
              "│    │    └─Dropout: 3-20                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-21              [64, 24, 256]             512\n",
              "│    └─EncoderLayer: 2-4                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-22              [64, 24, 256]             512\n",
              "│    │    └─MultiheadAttention: 3-23     [64, 24, 256]             263,168\n",
              "│    │    └─Dropout: 3-24                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-25              [64, 24, 256]             512\n",
              "│    │    └─Sequential: 3-26             [64, 24, 256]             525,568\n",
              "│    │    └─Dropout: 3-27                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-28              [64, 24, 256]             512\n",
              "│    └─EncoderLayer: 2-5                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-29              [64, 24, 256]             512\n",
              "│    │    └─MultiheadAttention: 3-30     [64, 24, 256]             263,168\n",
              "│    │    └─Dropout: 3-31                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-32              [64, 24, 256]             512\n",
              "│    │    └─Sequential: 3-33             [64, 24, 256]             525,568\n",
              "│    │    └─Dropout: 3-34                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-35              [64, 24, 256]             512\n",
              "│    └─EncoderLayer: 2-6                 [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-36              [64, 24, 256]             512\n",
              "│    │    └─MultiheadAttention: 3-37     [64, 24, 256]             263,168\n",
              "│    │    └─Dropout: 3-38                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-39              [64, 24, 256]             512\n",
              "│    │    └─Sequential: 3-40             [64, 24, 256]             525,568\n",
              "│    │    └─Dropout: 3-41                [64, 24, 256]             --\n",
              "│    │    └─LayerNorm: 3-42              [64, 24, 256]             512\n",
              "├─AdaptiveAvgPool1d: 1-5                 [64, 24, 1]               --\n",
              "├─LayerNorm: 1-6                         [64, 24]                  48\n",
              "├─Linear: 1-7                            [64, 1]                   25\n",
              "==========================================================================================\n",
              "Total params: 4,743,753\n",
              "Trainable params: 4,743,753\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 202.54\n",
              "==========================================================================================\n",
              "Input size (MB): 0.04\n",
              "Forward/backward pass size (MB): 154.15\n",
              "Params size (MB): 12.66\n",
              "Estimated Total Size (MB): 166.86\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Metrics"
      ],
      "metadata": {
        "id": "gZKJ0DFzQLEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dir_acc(y_true, y_pred):\n",
        "    mean, std = (y_true[:, 2], y_true[:, 3])\n",
        "    y_true_prev = (y_true[:, 0] * std) + mean\n",
        "    y_true_next = (y_true[:, 1] * std) + mean\n",
        "    y_pred_next = (y_pred[:, 0] * std) + mean\n",
        "\n",
        "    true_change = y_true_next - y_true_prev\n",
        "    pred_change = y_pred_next - y_true_prev\n",
        "\n",
        "    correct_direction = torch.eq(torch.sign(true_change), torch.sign(pred_change)).float()\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "\n",
        "    return torch.mean(correct_direction)"
      ],
      "metadata": {
        "id": "ubyNBvOmIl8R"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Validate"
      ],
      "metadata": {
        "id": "WrccPwx6Xk93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, criterion, optimizer, scheduler, scaler, train_loader):\n",
        "    model.train()\n",
        "\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "    running_loss = 0.0\n",
        "    running_dir = 0.0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      sequence, label = batch\n",
        "      sequence = sequence.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        output = model(sequence)\n",
        "        loss = criterion(output[:, 0], label[:, 1])\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      running_dir += dir_acc(label, output)\n",
        "\n",
        "      batch_bar.set_postfix(\n",
        "          loss=f\"{running_loss / (i + 1):.4f}\",\n",
        "          direction=f\"{running_dir / (i + 1):.4f}\"\n",
        "      )\n",
        "      batch_bar.update()\n",
        "\n",
        "      del sequence, label\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    return running_loss / len(train_loader), running_dir / len(train_loader)"
      ],
      "metadata": {
        "id": "5ZAMKmGdXoV4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_step(model, criterion, val_loader):\n",
        "    model.eval()\n",
        "\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, leave=False, position=0, desc='Validate')\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_dir = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            sequence, label = batch\n",
        "\n",
        "            sequence = sequence.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = model(sequence)\n",
        "            loss = criterion(output[:, 0], label[:, 1])\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_dir += dir_acc(label, output)\n",
        "\n",
        "            batch_bar.set_postfix(\n",
        "                loss=f\"{running_loss / (i + 1):.4f}\",\n",
        "                direction=f\"{running_dir / (i + 1):.4f}\"\n",
        "            )\n",
        "            batch_bar.update()\n",
        "\n",
        "            del sequence, label\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    return running_loss / len(val_loader), running_dir / len(val_loader)"
      ],
      "metadata": {
        "id": "FRVC4AOCLD1i"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss/Optimizer/Scheduler"
      ],
      "metadata": {
        "id": "8MKe2reVCCFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = torch.nn.L1Loss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "optimizer = None\n",
        "if config[\"optimizer\"] == \"SGD\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(),\n",
        "                                lr=config[\"learning_rate\"],\n",
        "                                momentum=config[\"momentum\"],\n",
        "                                weight_decay=1E-4,\n",
        "                                nesterov=config[\"nesterov\"])\n",
        "\n",
        "elif config[\"optimizer\"] == \"Adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                lr=float(config[\"learning_rate\"]),weight_decay=0.01 )\n",
        "\n",
        "elif config[\"optimizer\"] == \"AdamW\":\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                                lr=float(config[\"learning_rate\"]),\n",
        "                                weight_decay=0.01)\n",
        "\n",
        "scheduler  =  None\n",
        "if config[\"scheduler\"] == \"ReduceLR\":\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                    factor=config[\"factor\"], patience=config[\"patience\"], min_lr=1E-8, threshold=1E-1)\n",
        "\n",
        "elif config[\"scheduler\"] == \"CosineAnnealing\":\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                    T_max = config[\"epochs\"], eta_min=1E-8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qre_mGAgCjdV",
        "outputId": "1813f87c-d851-4990-8beb-52b4e6315bf6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-0f2ac57bdc54>:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ],
      "metadata": {
        "id": "gDpTqmoOtfFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, optimizer=None, scheduler=None, path='./checkpoint.pth'):\n",
        "    checkpoint = torch.load(path, map_location=torch.device(device))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    else:\n",
        "        optimizer = None\n",
        "    if scheduler is not None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    else:\n",
        "        scheduler = None\n",
        "    epoch = checkpoint['epoch']\n",
        "    return model, optimizer, scheduler, epoch"
      ],
      "metadata": {
        "id": "IraKPfmftgqJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "cOSaPnKlG8xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    if not (isinstance(metric, tuple) and len(metric) == 2):\n",
        "        raise ValueError(\"metric must be a tuple in the form (name, value)\")\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"scheduler_state_dict\": scheduler.state_dict() if scheduler else {},\n",
        "            metric[0]: metric[1],  # Unpacks the metric name and value\n",
        "            \"epoch\": epoch\n",
        "        },\n",
        "        path\n",
        "    )"
      ],
      "metadata": {
        "id": "5Ri8Hii1G-LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "dAewHnxeEdz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "best_dir = 0.5\n",
        "\n",
        "e = 0\n",
        "epochs = config[\"epochs\"]\n",
        "for epoch in range(e, epochs):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, epochs))\n",
        "\n",
        "    curr_lr = float(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    train_loss, train_dir = train_step(model, loss_func, optimizer, scheduler, scaler, trainLoader)\n",
        "\n",
        "    print(\"\\nEpoch {}/{}: \\nTrain Loss {:.04f}\\t Train Direction {:.04f}\\t Learning Rate {:.06f}\".format(\n",
        "        epoch + 1, epochs, train_loss, train_dir, curr_lr))\n",
        "\n",
        "    val_loss, val_dir = validate_step(model, loss_func, valLoader)\n",
        "\n",
        "    print(\"Loss       : {:.04f}\".format(val_loss))\n",
        "    print(\"Direction  : {:.04f}\".format(val_dir))\n",
        "\n",
        "    if config[\"scheduler\"] == \"ReduceLR\":\n",
        "        scheduler.step(val_dir)\n",
        "    else:\n",
        "        scheduler.step()\n",
        "\n",
        "    if val_dir >= best_dir:\n",
        "      best_dir = val_dir\n",
        "      save_model(model, optimizer, scheduler, (\"val_dir\", val_dir), epoch, \"best_dir.pth\")\n",
        "      print(\"Saved best direction model\")\n",
        "\n",
        "    save_model(model, optimizer, scheduler, (\"val_dir\", val_dir), epoch, \"last.pth\")\n",
        "    print(\"Saved last model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmBNjwc5EfGN",
        "outputId": "f5168f69-0658-4b11-e308-171a668e5ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/820 [00:00<?, ?it/s]<ipython-input-51-cca2f6c9d213>:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/100: \n",
            "Train Loss 0.1908\t Train Direction 0.5215\t Learning Rate 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1383\n",
            "Direction  : 0.5089\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/100: \n",
            "Train Loss 0.1449\t Train Direction 0.5222\t Learning Rate 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1540\n",
            "Direction  : 0.5092\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/100: \n",
            "Train Loss 0.1387\t Train Direction 0.5283\t Learning Rate 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1429\n",
            "Direction  : 0.5185\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/100: \n",
            "Train Loss 0.1369\t Train Direction 0.5311\t Learning Rate 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1531\n",
            "Direction  : 0.5058\n",
            "Saved last model\n",
            "\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/100: \n",
            "Train Loss 0.1329\t Train Direction 0.5371\t Learning Rate 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1553\n",
            "Direction  : 0.5293\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/100: \n",
            "Train Loss 0.1317\t Train Direction 0.5397\t Learning Rate 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1336\n",
            "Direction  : 0.5445\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/100: \n",
            "Train Loss 0.1308\t Train Direction 0.5408\t Learning Rate 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1383\n",
            "Direction  : 0.5351\n",
            "Saved last model\n",
            "\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/100: \n",
            "Train Loss 0.1289\t Train Direction 0.5493\t Learning Rate 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1566\n",
            "Direction  : 0.5239\n",
            "Saved last model\n",
            "\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/100: \n",
            "Train Loss 0.1286\t Train Direction 0.5507\t Learning Rate 0.000197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1264\n",
            "Direction  : 0.5828\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/100: \n",
            "Train Loss 0.1266\t Train Direction 0.5546\t Learning Rate 0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1391\n",
            "Direction  : 0.5402\n",
            "Saved last model\n",
            "\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11/100: \n",
            "Train Loss 0.1268\t Train Direction 0.5614\t Learning Rate 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1473\n",
            "Direction  : 0.5367\n",
            "Saved last model\n",
            "\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12/100: \n",
            "Train Loss 0.1253\t Train Direction 0.5624\t Learning Rate 0.000194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1400\n",
            "Direction  : 0.5425\n",
            "Saved last model\n",
            "\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13/100: \n",
            "Train Loss 0.1238\t Train Direction 0.5702\t Learning Rate 0.000193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1451\n",
            "Direction  : 0.5398\n",
            "Saved last model\n",
            "\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14/100: \n",
            "Train Loss 0.1222\t Train Direction 0.5770\t Learning Rate 0.000192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1275\n",
            "Direction  : 0.5473\n",
            "Saved last model\n",
            "\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15/100: \n",
            "Train Loss 0.1219\t Train Direction 0.5768\t Learning Rate 0.000190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1283\n",
            "Direction  : 0.5636\n",
            "Saved last model\n",
            "\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16/100: \n",
            "Train Loss 0.1213\t Train Direction 0.5783\t Learning Rate 0.000189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1365\n",
            "Direction  : 0.5540\n",
            "Saved last model\n",
            "\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17/100: \n",
            "Train Loss 0.1204\t Train Direction 0.5881\t Learning Rate 0.000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1314\n",
            "Direction  : 0.5612\n",
            "Saved last model\n",
            "\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18/100: \n",
            "Train Loss 0.1197\t Train Direction 0.5866\t Learning Rate 0.000186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1270\n",
            "Direction  : 0.5873\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19/100: \n",
            "Train Loss 0.1185\t Train Direction 0.5934\t Learning Rate 0.000184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1309\n",
            "Direction  : 0.5853\n",
            "Saved last model\n",
            "\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20/100: \n",
            "Train Loss 0.1171\t Train Direction 0.6036\t Learning Rate 0.000183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1220\n",
            "Direction  : 0.5911\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21/100: \n",
            "Train Loss 0.1161\t Train Direction 0.6050\t Learning Rate 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1258\n",
            "Direction  : 0.5985\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22/100: \n",
            "Train Loss 0.1154\t Train Direction 0.6073\t Learning Rate 0.000179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1329\n",
            "Direction  : 0.5769\n",
            "Saved last model\n",
            "\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23/100: \n",
            "Train Loss 0.1142\t Train Direction 0.6123\t Learning Rate 0.000177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1538\n",
            "Direction  : 0.5582\n",
            "Saved last model\n",
            "\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24/100: \n",
            "Train Loss 0.1137\t Train Direction 0.6162\t Learning Rate 0.000175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1244\n",
            "Direction  : 0.5965\n",
            "Saved last model\n",
            "\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25/100: \n",
            "Train Loss 0.1124\t Train Direction 0.6231\t Learning Rate 0.000173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1181\n",
            "Direction  : 0.5965\n",
            "Saved last model\n",
            "\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 26/100: \n",
            "Train Loss 0.1110\t Train Direction 0.6248\t Learning Rate 0.000171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1395\n",
            "Direction  : 0.5792\n",
            "Saved last model\n",
            "\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 27/100: \n",
            "Train Loss 0.1104\t Train Direction 0.6288\t Learning Rate 0.000168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1278\n",
            "Direction  : 0.5962\n",
            "Saved last model\n",
            "\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 28/100: \n",
            "Train Loss 0.1090\t Train Direction 0.6367\t Learning Rate 0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1434\n",
            "Direction  : 0.5782\n",
            "Saved last model\n",
            "\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 29/100: \n",
            "Train Loss 0.1083\t Train Direction 0.6403\t Learning Rate 0.000164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1211\n",
            "Direction  : 0.6074\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30/100: \n",
            "Train Loss 0.1068\t Train Direction 0.6433\t Learning Rate 0.000161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1110\n",
            "Direction  : 0.6301\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 31/100: \n",
            "Train Loss 0.1057\t Train Direction 0.6510\t Learning Rate 0.000159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1277\n",
            "Direction  : 0.6002\n",
            "Saved last model\n",
            "\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 32/100: \n",
            "Train Loss 0.1045\t Train Direction 0.6528\t Learning Rate 0.000156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1174\n",
            "Direction  : 0.6359\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 33/100: \n",
            "Train Loss 0.1041\t Train Direction 0.6570\t Learning Rate 0.000154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1182\n",
            "Direction  : 0.6233\n",
            "Saved last model\n",
            "\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 34/100: \n",
            "Train Loss 0.1027\t Train Direction 0.6594\t Learning Rate 0.000151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1220\n",
            "Direction  : 0.6230\n",
            "Saved last model\n",
            "\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 35/100: \n",
            "Train Loss 0.1016\t Train Direction 0.6662\t Learning Rate 0.000148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1212\n",
            "Direction  : 0.6288\n",
            "Saved last model\n",
            "\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 36/100: \n",
            "Train Loss 0.1000\t Train Direction 0.6711\t Learning Rate 0.000145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1120\n",
            "Direction  : 0.6542\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 37/100: \n",
            "Train Loss 0.0992\t Train Direction 0.6773\t Learning Rate 0.000143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1062\n",
            "Direction  : 0.6731\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 38/100: \n",
            "Train Loss 0.0978\t Train Direction 0.6809\t Learning Rate 0.000140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1149\n",
            "Direction  : 0.6321\n",
            "Saved last model\n",
            "\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 39/100: \n",
            "Train Loss 0.0969\t Train Direction 0.6864\t Learning Rate 0.000137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1156\n",
            "Direction  : 0.6590\n",
            "Saved last model\n",
            "\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 40/100: \n",
            "Train Loss 0.0957\t Train Direction 0.6885\t Learning Rate 0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1164\n",
            "Direction  : 0.6528\n",
            "Saved last model\n",
            "\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 41/100: \n",
            "Train Loss 0.0944\t Train Direction 0.6985\t Learning Rate 0.000131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1190\n",
            "Direction  : 0.6559\n",
            "Saved last model\n",
            "\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 42/100: \n",
            "Train Loss 0.0930\t Train Direction 0.7005\t Learning Rate 0.000128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1036\n",
            "Direction  : 0.6870\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 43/100: \n",
            "Train Loss 0.0924\t Train Direction 0.7026\t Learning Rate 0.000125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1165\n",
            "Direction  : 0.6552\n",
            "Saved last model\n",
            "\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 44/100: \n",
            "Train Loss 0.0914\t Train Direction 0.7063\t Learning Rate 0.000122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1119\n",
            "Direction  : 0.6853\n",
            "Saved last model\n",
            "\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 45/100: \n",
            "Train Loss 0.0901\t Train Direction 0.7121\t Learning Rate 0.000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1108\n",
            "Direction  : 0.6596\n",
            "Saved last model\n",
            "\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 46/100: \n",
            "Train Loss 0.0895\t Train Direction 0.7133\t Learning Rate 0.000116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1294\n",
            "Direction  : 0.6396\n",
            "Saved last model\n",
            "\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 47/100: \n",
            "Train Loss 0.0881\t Train Direction 0.7164\t Learning Rate 0.000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1119\n",
            "Direction  : 0.6623\n",
            "Saved last model\n",
            "\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 48/100: \n",
            "Train Loss 0.0871\t Train Direction 0.7223\t Learning Rate 0.000109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1120\n",
            "Direction  : 0.6722\n",
            "Saved last model\n",
            "\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 49/100: \n",
            "Train Loss 0.0855\t Train Direction 0.7284\t Learning Rate 0.000106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1022\n",
            "Direction  : 0.7024\n",
            "Saved best direction model\n",
            "Saved last model\n",
            "\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 50/100: \n",
            "Train Loss 0.0844\t Train Direction 0.7324\t Learning Rate 0.000103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1013\n",
            "Direction  : 0.6956\n",
            "Saved last model\n",
            "\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 51/100: \n",
            "Train Loss 0.0836\t Train Direction 0.7345\t Learning Rate 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss       : 0.1154\n",
            "Direction  : 0.6637\n",
            "Saved last model\n",
            "\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 52/100: \n",
            "Train Loss 0.0824\t Train Direction 0.7373\t Learning Rate 0.000097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validate:  28%|██▊       | 13/46 [00:00<00:00, 33.29it/s, direction=0.6819, loss=0.1130]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "F250BOn2ZehS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validate_step(model, loss_func, testLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUIHQRqfHukS",
        "outputId": "75148ee1-c284-45cd-fab6-471973a1daaa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.06687977456528207, tensor(0.8112))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, scheduler, epoch = load_model(model, optimizer, scheduler, \"best_dir (3).pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLahtfbj7ulr",
        "outputId": "f36960c1-5ac8-44af-f99d-c209c473a7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-45b60bc1d03b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=torch.device(device))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Usage"
      ],
      "metadata": {
        "id": "bSyVYOO-ZgWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, scheduler, epoch = load_model(model, optimizer, scheduler, \"best_dir(79.83).pth\")\n",
        "\n",
        "data = yf.download('MSFT', interval='5m', period='5d')\n",
        "\n",
        "close = data['Close']\n",
        "upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n",
        "width = upper - lower\n",
        "rsi = calculate_rsi(close, window=14)\n",
        "roc = calculate_roc(close, periods=14)\n",
        "volume = data['Volume']\n",
        "diff = data['Close'].diff(1)\n",
        "percent_change_close = data['Close'].pct_change() * 100\n",
        "print(data.tail())\n",
        "\n",
        "data = pd.DataFrame({\n",
        "  'close': [i[0] for i in close.values.tolist()],\n",
        "  'width': [i[0] for i in width.values.tolist()],\n",
        "  'rsi': [i[0] for i in rsi.values.tolist()],\n",
        "  'roc': [i[0] for i in roc.values.tolist()],\n",
        "  'volume': [i[0] for i in volume.values.tolist()],\n",
        "  'diff': [i[0] for i in diff.values.tolist()],\n",
        "  'percent_change_close': [i[0] for i in percent_change_close.values.tolist()],\n",
        "})\n",
        "\n",
        "mean = data.mean()\n",
        "std = data.std()\n",
        "\n",
        "data = (data - mean) / (std)\n",
        "\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "close = data['close'].values\n",
        "width = data['width'].values\n",
        "rsi = data['rsi'].values\n",
        "roc = data['roc'].values\n",
        "volume = data['volume'].values\n",
        "diff = data['diff'].values\n",
        "pct_change = data['percent_change_close'].values\n",
        "\n",
        "ticker_data = np.column_stack((close,\n",
        "                              width,\n",
        "                              rsi,\n",
        "                              roc,\n",
        "                              volume,\n",
        "                              diff,\n",
        "                              pct_change))\n",
        "\n",
        "sequence = np.array(ticker_data[len(ticker_data) - config[\"history_length\"]:])\n",
        "sequence = torch.FloatTensor(sequence).unsqueeze(0).to(device)\n",
        "\n",
        "model.eval()\n",
        "output = model(sequence)\n",
        "\n",
        "output = output[0] * std['close'] + mean['close']\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EDXce7pZjvL",
        "outputId": "3999f3b6-8fb7-4fc3-e318-48808b336621"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-45b60bc1d03b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(path, map_location=torch.device(device))\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price                           Close        High         Low        Open  \\\n",
            "Ticker                           MSFT        MSFT        MSFT        MSFT   \n",
            "Datetime                                                                    \n",
            "2025-01-10 16:30:00+00:00  417.299988  417.873993  417.089996  417.459991   \n",
            "2025-01-10 16:35:00+00:00  416.880005  417.410004  416.480011  417.338593   \n",
            "2025-01-10 16:40:00+00:00  418.075012  418.075012  416.910004  417.230011   \n",
            "2025-01-10 16:45:00+00:00  417.404999  418.320007  417.299988  417.980011   \n",
            "2025-01-10 16:50:00+00:00  417.635010  417.949493  417.404999  417.404999   \n",
            "\n",
            "Price                     Volume  \n",
            "Ticker                      MSFT  \n",
            "Datetime                          \n",
            "2025-01-10 16:30:00+00:00  81170  \n",
            "2025-01-10 16:35:00+00:00  92202  \n",
            "2025-01-10 16:40:00+00:00  79633  \n",
            "2025-01-10 16:45:00+00:00  76183  \n",
            "2025-01-10 16:50:00+00:00  12938  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(418.3689, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}