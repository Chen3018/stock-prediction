{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG1IlQIqSPcS"
      },
      "source": [
        "Data preprocessing and model metrics inspired by\n",
        "https://medium.com/@Matthew_Frank/stock-price-prediction-using-transformers-2d84341ff213"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0j3IEzlozpvk"
      },
      "outputs": [],
      "source": [
        "%pip install torchinfo -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4EgHySQ1sfY"
      },
      "source": [
        "Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ynMRh-2p1iKg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import yaml\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import math\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIYYHdXr2Auc"
      },
      "source": [
        "Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiwqEEDb2DYP",
        "outputId": "4ac51a2f-bcde-4e94-81d8-6f6bedbdca1b"
      },
      "outputs": [],
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "###### Dataset -----------------------------------------------------------------\n",
        "tickers                   : ['META', 'AAPL', 'MSFT', 'AMZN', 'GOOG', 'NVDA', 'GOOGL', 'TSLA', 'AVGO', 'WMT', 'LLY', 'JPM', 'V', 'UNH', 'MA', 'XOM', 'ORCL', 'COST', 'HD', 'PG']\n",
        "period                    : '10y'\n",
        "interval                  : '5m'\n",
        "start_date                : '2024-11-12'\n",
        "end_date                  : '2025-01-09'\n",
        "history_length            : 24\n",
        "prediction_length         : 12\n",
        "NUM_WORKERS               : 4\n",
        "batch_size                : 64\n",
        "\n",
        "###### Network Specs -------------------------------------------------------------\n",
        "d_model                   : 256\n",
        "d_ff                      : 1024\n",
        "\n",
        "###### Encoder Specs -------------------------------------------------------------\n",
        "enc_dropout               : 0.25\n",
        "enc_num_layers            : 6\n",
        "enc_num_heads             : 8\n",
        "\n",
        "###### Base Parameters -----------------------------------------------------------\n",
        "optimizer                 : \"AdamW\"\n",
        "momentum                  : 0.0\n",
        "nesterov                  : True\n",
        "learning_rate             : 2E-4\n",
        "scheduler                 : \"CosineAnnealing\"\n",
        "factor                    : 0.2\n",
        "patience                  : 2\n",
        "epochs                    : 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XiyZVE5x2lt6"
      },
      "outputs": [],
      "source": [
        "with open(\"config.yaml\") as file:\n",
        "    config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugRF1dJ5CA5Z"
      },
      "source": [
        "Helper Functions for Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8SxGjNXRB_xH"
      },
      "outputs": [],
      "source": [
        "def calculate_bollinger_bands(data, window=10, num_of_std=2):\n",
        "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
        "    rolling_mean = data.rolling(window=window).mean()\n",
        "    rolling_std = data.rolling(window=window).std()\n",
        "    upper_band = rolling_mean + (rolling_std * num_of_std)\n",
        "    lower_band = rolling_mean - (rolling_std * num_of_std)\n",
        "    return upper_band, lower_band\n",
        "\n",
        "def calculate_rsi(data, window=10):\n",
        "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "    delta = data.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
        "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "def calculate_roc(data, periods=10):\n",
        "    \"\"\"Calculate Rate of Change.\"\"\"\n",
        "    roc = ((data - data.shift(periods)) / data.shift(periods)) * 100\n",
        "    return roc\n",
        "\n",
        "def create_sequences(data, labels, mean, std, history_length, prediction_length):\n",
        "    sequences = []\n",
        "    lab = []\n",
        "    data_size = len(data)\n",
        "\n",
        "    for i in range(data_size - (history_length + prediction_length + 1)):\n",
        "        if i == 0:\n",
        "          continue\n",
        "        sequences.append(data[i:i + history_length])\n",
        "        lab.append([labels[i-1], labels[i + prediction_length], mean, std])\n",
        "\n",
        "    return np.array(sequences), np.array(lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVCzCTLQ3w3e"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "94ddCywL3yed"
      },
      "outputs": [],
      "source": [
        "class StockPriceDataset(Dataset):\n",
        "\n",
        "  def __init__(self, config):\n",
        "    dataByTicker = []\n",
        "    stats = {}\n",
        "\n",
        "    for ticker in config[\"tickers\"]:\n",
        "      data = yf.download(ticker, interval=config[\"interval\"], start=config[\"start_date\"], end=config[\"end_date\"])\n",
        "      #data = yf.download(ticker, interval=config[\"interval\"], period=config[\"period\"])\n",
        "\n",
        "      close = data['Close']\n",
        "      upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n",
        "      width = upper - lower\n",
        "      rsi = calculate_rsi(close, window=14)\n",
        "      roc = calculate_roc(close, periods=14)\n",
        "      volume = data['Volume']\n",
        "      diff = data['Close'].diff(1)\n",
        "      percent_change_close = data['Close'].pct_change() * 100\n",
        "\n",
        "      ticker_df = pd.DataFrame({\n",
        "        ticker+'_close': [i[0] for i in close.values.tolist()],\n",
        "        ticker+'_width': [i[0] for i in width.values.tolist()],\n",
        "        ticker+'_rsi': [i[0] for i in rsi.values.tolist()],\n",
        "        ticker+'_roc': [i[0] for i in roc.values.tolist()],\n",
        "        ticker+'_volume': [i[0] for i in volume.values.tolist()],\n",
        "        ticker+'_diff': [i[0] for i in diff.values.tolist()],\n",
        "        ticker+'_percent_change_close': [i[0] for i in percent_change_close.values.tolist()],\n",
        "      })\n",
        "\n",
        "      mean = ticker_df.mean()\n",
        "      std = ticker_df.std()\n",
        "      for column in mean.index:\n",
        "        stats[f\"{column}_mean\"] = mean[column]\n",
        "        stats[f\"{column}_std\"] = std[column]\n",
        "\n",
        "      ticker_df = (ticker_df - mean) / (std)\n",
        "\n",
        "      dataByTicker.append(ticker_df)\n",
        "\n",
        "    stats = pd.DataFrame([stats], index=[0])\n",
        "\n",
        "    data = pd.concat(dataByTicker, axis=1)\n",
        "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    labels = data.shift(-1)\n",
        "\n",
        "    data = data.iloc[:-1]\n",
        "    labels = labels.iloc[:-1]\n",
        "\n",
        "    all_sequences = []\n",
        "    all_labels = []\n",
        "    for ticker in config[\"tickers\"]:\n",
        "\n",
        "        # Extract close and volume data for the ticker\n",
        "        close = data[ticker+'_close'].values\n",
        "        width = data[ticker+'_width'].values\n",
        "        rsi = data[ticker+'_rsi'].values\n",
        "        roc = data[ticker+'_roc'].values\n",
        "        volume = data[ticker+'_volume'].values\n",
        "        diff = data[ticker+'_diff'].values\n",
        "        pct_change = data[ticker+'_percent_change_close'].values\n",
        "\n",
        "        # Combine close and volume data\n",
        "        ticker_data = np.column_stack((close,\n",
        "                                      width,\n",
        "                                      rsi,\n",
        "                                      roc,\n",
        "                                      volume,\n",
        "                                      diff,\n",
        "                                      pct_change))\n",
        "\n",
        "        # Generate sequences\n",
        "        attribute = ticker+\"_close\"\n",
        "        ticker_sequences, lab = create_sequences(ticker_data,\n",
        "                                                labels[attribute].values[config[\"history_length\"]-1:],\n",
        "                                                stats[attribute+\"_mean\"].values[0],\n",
        "                                                stats[attribute+\"_std\"].values[0],\n",
        "                                                config[\"history_length\"],\n",
        "                                                config[\"prediction_length\"],)\n",
        "\n",
        "        all_sequences.extend(ticker_sequences)\n",
        "        all_labels.extend(lab)\n",
        "    self.sequences = np.array(all_sequences)\n",
        "    self.labels = np.array(all_labels)\n",
        "    self.length = len(self.sequences)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return torch.FloatTensor(self.sequences[index]), torch.FloatTensor(self.labels[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXYuSf1W_-O5",
        "outputId": "a24b5811-57ec-468c-82eb-fe8e55c85891"
      },
      "outputs": [],
      "source": [
        "generator = torch.Generator().manual_seed(42)\n",
        "dataset = StockPriceDataset(config)\n",
        "trainDataset, valDataset, testDataset = torch.utils.data.random_split(dataset, [0.9, 0.05, 0.05], generator=generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QrFN5CyWMNI"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P53gVwsJSZNs",
        "outputId": "9dacd230-3559-4553-e546-fd76d07edb57"
      },
      "outputs": [],
      "source": [
        "trainLoader = DataLoader(dataset=trainDataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=config[\"NUM_WORKERS\"])\n",
        "\n",
        "valLoader = DataLoader(dataset=valDataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"NUM_WORKERS\"])\n",
        "\n",
        "testLoader = DataLoader(dataset=testDataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=config[\"NUM_WORKERS\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MyRewBrLf2-"
      },
      "source": [
        "Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QdEPL2uuzRrq"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(torch.nn.Module):\n",
        "    ''' Position Encoding from Attention Is All You Need Paper '''\n",
        "\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize a tensor to hold the positional encodings\n",
        "        pe          = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Create a tensor representing the positions (0 to max_len-1)\n",
        "        position    = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # Calculate the division term for the sine and cosine functions\n",
        "        # This term creates a series of values that decrease geometrically, used to generate varying frequencies for positional encodings\n",
        "        div_term    = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Compute the positional encodings using sine and cosine functions\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Reshape the positional encodings tensor and make it a buffer\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "      return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d848j8WmiOOg"
      },
      "source": [
        "Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uDOVzFY7iR1C"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(torch.nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.pre_norm = torch.nn.LayerNorm(d_model)\n",
        "        self.self_attn = torch.nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.ffn1 = torch.nn.Sequential(\n",
        "            torch.nn.Linear(d_model, d_ff),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            torch.nn.Linear(d_ff, d_model),\n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.norm1 = torch.nn.LayerNorm(d_model)\n",
        "        self.norm2 = torch.nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = self.pre_norm(x)\n",
        "\n",
        "        x_attn, _ = self.self_attn(x_norm, x_norm, x_norm)\n",
        "\n",
        "        x_norm = self.norm1(x + self.dropout(x_attn))\n",
        "\n",
        "        x_ffn = self.ffn1(x_norm)\n",
        "\n",
        "        x = self.norm2(x_norm + self.dropout(x_ffn))\n",
        "\n",
        "        return x\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_layers,\n",
        "                 d_model,\n",
        "                 num_heads,\n",
        "                 history_length,\n",
        "                 d_ff,\n",
        "                 dropout=0.1):\n",
        "\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.upscale = torch.nn.Linear(7, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model, history_length)\n",
        "        self.dropout =  torch.nn.Dropout(dropout)\n",
        "        self.enc_layers =  torch.nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.average_pool = torch.nn.AdaptiveAvgPool1d(1)\n",
        "        self.after_norm =  torch.nn.LayerNorm(history_length)\n",
        "        self.ctc_head   =  torch.nn.Linear(history_length, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.upscale(x)\n",
        "\n",
        "        x_pos = self.pos_encoding(x)\n",
        "\n",
        "        x_drop = self.dropout(x_pos)\n",
        "\n",
        "        x_res = x + x_drop\n",
        "\n",
        "        for layer in self.enc_layers:\n",
        "            x_res = layer(x_res)\n",
        "\n",
        "        x_res = torch.squeeze(self.average_pool(x_res))\n",
        "\n",
        "        x = self.after_norm(x_res)\n",
        "\n",
        "        x_ctc = self.ctc_head(x)\n",
        "        # I know I should be returning x_ctc, but for some reason I made the mistake of returning x and it worked better\n",
        "        # Likely due to over fitting, an issue I will fix\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtBWDE_uw5MB"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQTMAwAfw431",
        "outputId": "93596302-5498-4e96-c630-65eeb78e6ade"
      },
      "outputs": [],
      "source": [
        "model = Encoder(config[\"enc_num_layers\"], config[\"d_model\"], config[\"enc_num_heads\"], config[\"history_length\"], config[\"d_ff\"], config[\"enc_dropout\"])\n",
        "\n",
        "sequence, label = next(iter(trainLoader))\n",
        "\n",
        "summary(model.to(device), input_data=[sequence.to(device)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZKJ0DFzQLEU"
      },
      "source": [
        "Custom Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ubyNBvOmIl8R"
      },
      "outputs": [],
      "source": [
        "def dir_acc(y_true, y_pred):\n",
        "    mean, std = (y_true[:, 2], y_true[:, 3])\n",
        "    y_true_prev = (y_true[:, 0] * std) + mean\n",
        "    y_true_next = (y_true[:, 1] * std) + mean\n",
        "    y_pred_next = (y_pred[:, 0] * std) + mean\n",
        "\n",
        "    true_change = y_true_next - y_true_prev\n",
        "    pred_change = y_pred_next - y_true_prev\n",
        "\n",
        "    correct_direction = torch.eq(torch.sign(true_change), torch.sign(pred_change)).float()\n",
        "    y_true = y_true.cpu().detach().numpy()\n",
        "\n",
        "    return torch.mean(correct_direction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrccPwx6Xk93"
      },
      "source": [
        "Train/Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5ZAMKmGdXoV4"
      },
      "outputs": [],
      "source": [
        "def train_step(model, criterion, optimizer, scheduler, scaler, train_loader):\n",
        "    model.train()\n",
        "\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "    running_loss = 0.0\n",
        "    running_dir = 0.0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      sequence, label = batch\n",
        "      sequence = sequence.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        output = model(sequence)\n",
        "        loss = criterion(output[:, 0], label[:, 1])\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      running_dir += dir_acc(label, output)\n",
        "\n",
        "      batch_bar.set_postfix(\n",
        "          loss=f\"{running_loss / (i + 1):.4f}\",\n",
        "          direction=f\"{running_dir / (i + 1):.4f}\"\n",
        "      )\n",
        "      batch_bar.update()\n",
        "\n",
        "      del sequence, label\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    return running_loss / len(train_loader), running_dir / len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FRVC4AOCLD1i"
      },
      "outputs": [],
      "source": [
        "def validate_step(model, criterion, val_loader):\n",
        "    model.eval()\n",
        "\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, leave=False, position=0, desc='Validate')\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_dir = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            sequence, label = batch\n",
        "\n",
        "            sequence = sequence.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = model(sequence)\n",
        "            loss = criterion(output[:, 0], label[:, 1])\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_dir += dir_acc(label, output)\n",
        "\n",
        "            batch_bar.set_postfix(\n",
        "                loss=f\"{running_loss / (i + 1):.4f}\",\n",
        "                direction=f\"{running_dir / (i + 1):.4f}\"\n",
        "            )\n",
        "            batch_bar.update()\n",
        "\n",
        "            del sequence, label\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    return running_loss / len(val_loader), running_dir / len(val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MKe2reVCCFQ"
      },
      "source": [
        "Loss/Optimizer/Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qre_mGAgCjdV",
        "outputId": "1813f87c-d851-4990-8beb-52b4e6315bf6"
      },
      "outputs": [],
      "source": [
        "loss_func = torch.nn.L1Loss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "optimizer = None\n",
        "if config[\"optimizer\"] == \"SGD\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(),\n",
        "                                lr=config[\"learning_rate\"],\n",
        "                                momentum=config[\"momentum\"],\n",
        "                                weight_decay=1E-4,\n",
        "                                nesterov=config[\"nesterov\"])\n",
        "\n",
        "elif config[\"optimizer\"] == \"Adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                lr=float(config[\"learning_rate\"]),weight_decay=0.01 )\n",
        "\n",
        "elif config[\"optimizer\"] == \"AdamW\":\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                                lr=float(config[\"learning_rate\"]),\n",
        "                                weight_decay=0.01)\n",
        "\n",
        "scheduler  =  None\n",
        "if config[\"scheduler\"] == \"ReduceLR\":\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                    factor=config[\"factor\"], patience=config[\"patience\"], min_lr=1E-8, threshold=1E-1)\n",
        "\n",
        "elif config[\"scheduler\"] == \"CosineAnnealing\":\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                    T_max = config[\"epochs\"], eta_min=1E-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDpTqmoOtfFw"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IraKPfmftgqJ"
      },
      "outputs": [],
      "source": [
        "def load_model(model, optimizer=None, scheduler=None, path='./checkpoint.pth'):\n",
        "    checkpoint = torch.load(path, map_location=torch.device(device))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    else:\n",
        "        optimizer = None\n",
        "    if scheduler is not None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    else:\n",
        "        scheduler = None\n",
        "    epoch = checkpoint['epoch']\n",
        "    return model, optimizer, scheduler, epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOSaPnKlG8xE"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ri8Hii1G-LS"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    if not (isinstance(metric, tuple) and len(metric) == 2):\n",
        "        raise ValueError(\"metric must be a tuple in the form (name, value)\")\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"scheduler_state_dict\": scheduler.state_dict() if scheduler else {},\n",
        "            metric[0]: metric[1],  # Unpacks the metric name and value\n",
        "            \"epoch\": epoch\n",
        "        },\n",
        "        path\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAewHnxeEdz-"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmBNjwc5EfGN",
        "outputId": "f5168f69-0658-4b11-e308-171a668e5ba8"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "best_dir = 0.5\n",
        "\n",
        "e = 0\n",
        "epochs = config[\"epochs\"]\n",
        "for epoch in range(e, epochs):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, epochs))\n",
        "\n",
        "    curr_lr = float(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "    train_loss, train_dir = train_step(model, loss_func, optimizer, scheduler, scaler, trainLoader)\n",
        "\n",
        "    print(\"\\nEpoch {}/{}: \\nTrain Loss {:.04f}\\t Train Direction {:.04f}\\t Learning Rate {:.06f}\".format(\n",
        "        epoch + 1, epochs, train_loss, train_dir, curr_lr))\n",
        "\n",
        "    val_loss, val_dir = validate_step(model, loss_func, valLoader)\n",
        "\n",
        "    print(\"Loss       : {:.04f}\".format(val_loss))\n",
        "    print(\"Direction  : {:.04f}\".format(val_dir))\n",
        "\n",
        "    if config[\"scheduler\"] == \"ReduceLR\":\n",
        "        scheduler.step(val_dir)\n",
        "    else:\n",
        "        scheduler.step()\n",
        "\n",
        "    if val_dir >= best_dir:\n",
        "      best_dir = val_dir\n",
        "      save_model(model, optimizer, scheduler, (\"val_dir\", val_dir), epoch, \"best_dir.pth\")\n",
        "      print(\"Saved best direction model\")\n",
        "\n",
        "    save_model(model, optimizer, scheduler, (\"val_dir\", val_dir), epoch, \"last.pth\")\n",
        "    print(\"Saved last model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F250BOn2ZehS"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUIHQRqfHukS",
        "outputId": "75148ee1-c284-45cd-fab6-471973a1daaa"
      },
      "outputs": [],
      "source": [
        "validate_step(model, loss_func, testLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLahtfbj7ulr",
        "outputId": "f36960c1-5ac8-44af-f99d-c209c473a7ad"
      },
      "outputs": [],
      "source": [
        "model, optimizer, scheduler, epoch = load_model(model, optimizer, scheduler, \"best_dir (3).pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSyVYOO-ZgWv"
      },
      "source": [
        "Model Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EDXce7pZjvL",
        "outputId": "3999f3b6-8fb7-4fc3-e318-48808b336621"
      },
      "outputs": [],
      "source": [
        "model, optimizer, scheduler, epoch = load_model(model, optimizer, scheduler, \"best_dir(79.83).pth\")\n",
        "\n",
        "data = yf.download('MSFT', interval='5m', period='5d')\n",
        "\n",
        "close = data['Close']\n",
        "upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n",
        "width = upper - lower\n",
        "rsi = calculate_rsi(close, window=14)\n",
        "roc = calculate_roc(close, periods=14)\n",
        "volume = data['Volume']\n",
        "diff = data['Close'].diff(1)\n",
        "percent_change_close = data['Close'].pct_change() * 100\n",
        "print(data.tail())\n",
        "\n",
        "data = pd.DataFrame({\n",
        "  'close': [i[0] for i in close.values.tolist()],\n",
        "  'width': [i[0] for i in width.values.tolist()],\n",
        "  'rsi': [i[0] for i in rsi.values.tolist()],\n",
        "  'roc': [i[0] for i in roc.values.tolist()],\n",
        "  'volume': [i[0] for i in volume.values.tolist()],\n",
        "  'diff': [i[0] for i in diff.values.tolist()],\n",
        "  'percent_change_close': [i[0] for i in percent_change_close.values.tolist()],\n",
        "})\n",
        "\n",
        "mean = data.mean()\n",
        "std = data.std()\n",
        "\n",
        "data = (data - mean) / (std)\n",
        "\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "close = data['close'].values\n",
        "width = data['width'].values\n",
        "rsi = data['rsi'].values\n",
        "roc = data['roc'].values\n",
        "volume = data['volume'].values\n",
        "diff = data['diff'].values\n",
        "pct_change = data['percent_change_close'].values\n",
        "\n",
        "ticker_data = np.column_stack((close,\n",
        "                              width,\n",
        "                              rsi,\n",
        "                              roc,\n",
        "                              volume,\n",
        "                              diff,\n",
        "                              pct_change))\n",
        "\n",
        "sequence = np.array(ticker_data[len(ticker_data) - config[\"history_length\"]:])\n",
        "sequence = torch.FloatTensor(sequence).unsqueeze(0).to(device)\n",
        "\n",
        "model.eval()\n",
        "output = model(sequence)\n",
        "\n",
        "output = output[0] * std['close'] + mean['close']\n",
        "\n",
        "output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
